{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
      ],
      "metadata": {
        "id": "0gaMEpTkSEG8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyHepkEARod5",
        "outputId": "9ed8d192-4f6c-40a4-d942-ec1470a951f9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Task 1: Decision Tree: \n",
            "Full Decision Tree\n",
            "Train Accuracy: 1.0\n",
            "Test Accuracy: 0.9473684210526315\n",
            "\n",
            "Pruned Decision Tree (max_depth=3)\n",
            "Train Accuracy: 0.978021978021978\n",
            "Test Accuracy: 0.9473684210526315\n",
            "--------------------------------------------------\n",
            "Task 2: Random Forest (100 trees) :\n",
            "Train Accuracy: 1.0\n",
            "Test Accuracy: 0.9649122807017544\n",
            "\n",
            "Top 5 Features (Random Forest):\n",
            "                 feature  importance\n",
            "23            worst area    0.153892\n",
            "27  worst concave points    0.144663\n",
            "7    mean concave points    0.106210\n",
            "20          worst radius    0.077987\n",
            "6         mean concavity    0.068001\n",
            "--------------------------------------------------\n",
            " Task 3: Gradient Boosting :\n",
            "learning_rate=0.01, n_estimators=50 -> Train Acc: 0.9780, Test Acc: 0.9561\n",
            "learning_rate=0.01, n_estimators=100 -> Train Acc: 0.9868, Test Acc: 0.9561\n",
            "learning_rate=0.01, n_estimators=200 -> Train Acc: 0.9934, Test Acc: 0.9561\n",
            "learning_rate=0.1, n_estimators=50 -> Train Acc: 1.0000, Test Acc: 0.9561\n",
            "learning_rate=0.1, n_estimators=100 -> Train Acc: 1.0000, Test Acc: 0.9561\n",
            "learning_rate=0.1, n_estimators=200 -> Train Acc: 1.0000, Test Acc: 0.9561\n",
            "\n",
            "Top 5 Features (Gradient Boosting):\n",
            "                 feature  importance\n",
            "7    mean concave points    0.450528\n",
            "27  worst concave points    0.240103\n",
            "20          worst radius    0.075589\n",
            "22       worst perimeter    0.051408\n",
            "21         worst texture    0.039886\n",
            "--------------------------------------------------\n",
            " Task 4:\n",
            "Decision Tree Full Test Acc: 0.9473684210526315\n",
            "Decision Tree Pruned Test Acc: 0.9473684210526315\n",
            "Random Forest Test Acc: 0.9649122807017544\n",
            "Gradient Boosting (default) Test Acc: 0.956140350877193\n"
          ]
        }
      ],
      "source": [
        "# Sheet 4 Assignment\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X = pd.DataFrame(data.data, columns=data.feature_names)\n",
        "y = data.target\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "\n",
        "# Task 1: Decision Tree (Full & Pruned)\n",
        "\n",
        "print(\" Task 1: Decision Tree: \")\n",
        "\n",
        "dt_full = DecisionTreeClassifier(random_state=42)\n",
        "dt_full.fit(X_train, y_train)\n",
        "print(\"Full Decision Tree\")\n",
        "print(\"Train Accuracy:\", dt_full.score(X_train, y_train))\n",
        "print(\"Test Accuracy:\", dt_full.score(X_test, y_test))\n",
        "\n",
        "dt_pruned = DecisionTreeClassifier(max_depth=3, random_state=42)\n",
        "dt_pruned.fit(X_train, y_train)\n",
        "print(\"\\nPruned Decision Tree (max_depth=3)\")\n",
        "print(\"Train Accuracy:\", dt_pruned.score(X_train, y_train))\n",
        "print(\"Test Accuracy:\", dt_pruned.score(X_test, y_test))\n",
        "print(\"-\"*50)\n",
        "\n",
        "# Task 2: Random Forest\n",
        "print(\"Task 2: Random Forest (100 trees) :\")\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "print(\"Train Accuracy:\", rf.score(X_train, y_train))\n",
        "print(\"Test Accuracy:\", rf.score(X_test, y_test))\n",
        "\n",
        "rf_importances = pd.DataFrame({\n",
        "    \"feature\": X.columns,\n",
        "    \"importance\": rf.feature_importances_\n",
        "}).sort_values(\"importance\", ascending=False)\n",
        "\n",
        "print(\"\\nTop 5 Features (Random Forest):\")\n",
        "print(rf_importances.head(5))\n",
        "print(\"-\"*50)\n",
        "\n",
        "# Task 3: Gradient Boosting (default + parameter tuning)\n",
        "print(\" Task 3: Gradient Boosting :\")\n",
        "learning_rates = [0.01, 0.1]\n",
        "n_estimators_list = [50, 100, 200]\n",
        "\n",
        "for lr in learning_rates:\n",
        "    for n_est in n_estimators_list:\n",
        "        gb = GradientBoostingClassifier(\n",
        "            learning_rate=lr,\n",
        "            n_estimators=n_est,\n",
        "            random_state=42\n",
        "        )\n",
        "        gb.fit(X_train, y_train)\n",
        "        train_acc = gb.score(X_train, y_train)\n",
        "        test_acc = gb.score(X_test, y_test)\n",
        "        print(f\"learning_rate={lr}, n_estimators={n_est} -> Train Acc: {train_acc:.4f}, Test Acc: {test_acc:.4f}\")\n",
        "\n",
        "gb_default = GradientBoostingClassifier(random_state=42)\n",
        "gb_default.fit(X_train, y_train)\n",
        "gb_importances = pd.DataFrame({\n",
        "    \"feature\": X.columns,\n",
        "    \"importance\": gb_default.feature_importances_\n",
        "}).sort_values(\"importance\", ascending=False)\n",
        "\n",
        "print(\"\\nTop 5 Features (Gradient Boosting):\")\n",
        "print(gb_importances.head(5))\n",
        "print(\"-\"*50)\n",
        "\n",
        "# Task 4\n",
        "print(\" Task 4:\")\n",
        "print(\"Decision Tree Full Test Acc:\", dt_full.score(X_test, y_test))\n",
        "print(\"Decision Tree Pruned Test Acc:\", dt_pruned.score(X_test, y_test))\n",
        "print(\"Random Forest Test Acc:\", rf.score(X_test, y_test))\n",
        "print(\"Gradient Boosting (default) Test Acc:\", gb_default.score(X_test, y_test))\n"
      ]
    }
  ]
}